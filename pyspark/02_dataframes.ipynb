{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d82fad-bb22-4da7-9d2a-68925c064ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7a5966-c01e-403b-ae78-2836e49a00b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/20 00:47:20 WARN Utils: Your hostname, Abhinavs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.5 instead (on interface en0)\n",
      "22/12/20 00:47:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/20 00:47:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/20 00:47:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('PySpark Dataframes').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82685219-4f73-4713-ad6a-6c57d854b747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Dataframes</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x122af4390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6117312d-5b35-4569-850b-889a6d5bc550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "df_pyspark = spark.read.option('header', 'true').csv('test_data-1.csv')\n",
    "\n",
    "# check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75bda01-68fb-40fd-b179-52bd4e47268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the dataset by inferring the datatypes\n",
    "\n",
    "df_pyspark = spark.read.option('header', 'true').csv('test_data-1.csv', inferSchema=True)\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ca036f-2134-49b9-80f2-bc6eddb4c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| Name|Age|Experience|\n",
      "+-----+---+----------+\n",
      "| John| 35|        12|\n",
      "| Jane| 34|        11|\n",
      "|Stacy| 28|         8|\n",
      "|Jimmy| 25|         5|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best way of reading dataset\n",
    "\n",
    "df_pyspark = spark.read.csv('test_data-1.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbcb8975-5ccf-4f80-b670-5003bfca4f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162b5a6a-59ea-4045-9ebe-e04a8f1e91c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='John', Age=35, Experience=12),\n",
       " Row(Name='Jane', Age=34, Experience=11),\n",
       " Row(Name='Stacy', Age=28, Experience=8)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 3 rows\n",
    "\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea238f65-be26-46a2-bda6-52c6165dcd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| Name|\n",
      "+-----+\n",
      "| John|\n",
      "| Jane|\n",
      "|Stacy|\n",
      "|Jimmy|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a particular column\n",
    "\n",
    "df_pyspark.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be84a942-3c3e-4a99-818d-cbab36ae3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| Name|Experience|\n",
      "+-----+----------+\n",
      "| John|        12|\n",
      "| Jane|        11|\n",
      "|Stacy|         8|\n",
      "|Jimmy|         5|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select multiple columns\n",
    "\n",
    "df_pyspark.select(['Name', 'Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34757663-e9b1-46c2-a27f-03d2ba27fd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23772c91-fed0-41ef-8954-a357be29d28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dc3d7a1-a13e-41f5-846f-154c6b9bcc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the dataframe\n",
    "\n",
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc9e63fd-29da-429b-af2d-be18da46d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------------------------+\n",
      "| Name|Age|Experience|Experience After 2 Years|\n",
      "+-----+---+----------+------------------------+\n",
      "| John| 35|        12|                      14|\n",
      "| Jane| 34|        11|                      13|\n",
      "|Stacy| 28|         8|                      10|\n",
      "|Jimmy| 25|         5|                       7|\n",
      "+-----+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding columns in the dataframe\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn('Experience After 2 Years', df_pyspark['Experience'] + 2)\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f547cb8d-e55b-44e1-85ca-f5e5244348e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| Name|Age|Experience|\n",
      "+-----+---+----------+\n",
      "| John| 35|        12|\n",
      "| Jane| 34|        11|\n",
      "|Stacy| 28|         8|\n",
      "|Jimmy| 25|         5|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the columns\n",
    "\n",
    "df_pyspark = df_pyspark.drop('Experience After 2 Years')\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c75d22be-7cff-4616-b449-c1d997eb7894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|New Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|    John| 35|        12|\n",
      "|    Jane| 34|        11|\n",
      "|   Stacy| 28|         8|\n",
      "|   Jimmy| 25|         5|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename the columns\n",
    "\n",
    "df_pyspark = df_pyspark.withColumnRenamed('Name', 'New Name')\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f9a35-5ef4-40a6-8e24-4be56746b865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
